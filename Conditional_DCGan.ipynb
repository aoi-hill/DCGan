{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar_Cond_DCGan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqUeaPcL1IR5CzeTu9Mcv3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aoi-hill/DCGan/blob/main/Conditional_DCGan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "\n",
        "    image_tensor = (image_tensor + 1) / 2\n",
        "    image_unflat = image_tensor.detach().cpu()\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mOmQrqJW2Kve"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QmR7CZgxqZ1G"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lssVPNKs2ES7",
        "outputId": "1cfda35e-7ea8-4b9f-cd53-8fb77c7dec6a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim=10, im_chan=1, hidden_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.gen = nn.Sequential(\n",
        "            self.make_gen_block(input_dim, hidden_dim*8, kernel_size=4, stride=1, padding=0),\n",
        "            self.make_gen_block(hidden_dim*8, hidden_dim * 4, kernel_size=4, stride=2, padding=1),\n",
        "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=2, padding=1),\n",
        "            self.make_gen_block(hidden_dim * 2, im_chan, kernel_size=4, stride=2, padding=1, final_layer=True)\n",
        "            #self.make_gen_block(hidden_dim, im_chan, kernel_size=4, stride=2, padding=1, final_layer=True),\n",
        "        )\n",
        "\n",
        "    def make_gen_block(self, input_dim, output_dim, kernel_size=3, stride=2, padding=0, final_layer=False):\n",
        "        if not final_layer:\n",
        "            return(nn.Sequential(\n",
        "                nn.ConvTranspose2d(input_dim, output_dim, kernel_size, stride, padding),\n",
        "                nn.BatchNorm2d(output_dim),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ))\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(input_dim, output_dim, kernel_size, stride, padding),\n",
        "                nn.Tanh())\n",
        "\n",
        "    def forward(self, noise):\n",
        "        x = noise.view(len(noise),self.input_dim,1,1)\n",
        "        return self.gen(x)\n",
        "\n",
        "def get_noise(n_samples, input_dim, device='cpu'):\n",
        "    return torch.randn(n_samples,input_dim).to(device)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "6VYXLR3h4p8Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cifar10_shape = (3,32,32)\n",
        "gen_inp = z_dim + 10\n",
        "gen1 = Generator(gen_inp,3).to(device)\n",
        "noise = get_noise(batch_size,z_dim,device)\n",
        "one_hot = get_one_hot_labels(labels.to(device), 10)\n",
        "gen_inp = combine_vectors(noise,one_hot)\n",
        "print(gen1(gen_inp).shape)"
      ],
      "metadata": {
        "id": "Y1ptin13ItkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, im_chan=1, hidden_dim=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            self.make_disc_block(im_chan, hidden_dim, begin=True),\n",
        "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
        "            self.make_disc_block(hidden_dim*2, hidden_dim * 4),\n",
        "            self.make_disc_block(hidden_dim*4, 1, final_layer=True)\n",
        "            #self.make_disc_block(hidden_dim*8, 1, final_layer=True),\n",
        "        )\n",
        "\n",
        "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, padding=1, final_layer=False, begin=False):\n",
        "\n",
        "        if not final_layer and not begin:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride, padding, bias=False),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "            )\n",
        "        elif not final_layer:\n",
        "             return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride,padding, bias=False),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size = 4, stride = 1 , padding= 0 , bias=False),\n",
        "            )\n",
        "\n",
        "    def forward(self, img):\n",
        "        disc_pred = self.disc(img)\n",
        "        return disc_pred.view(len(disc_pred), -1)\n"
      ],
      "metadata": {
        "id": "i1YSRZ_w9FQK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def get_one_hot_labels(labels, n_classes):\n",
        "    return F.one_hot(labels, n_classes)"
      ],
      "metadata": {
        "id": "9Ken3Gh7AiU6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_vectors(x, y):\n",
        "    return torch.cat((x,y),dim=1)"
      ],
      "metadata": {
        "id": "C3gV3RWZCHCE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=128\n",
        "n_epochs = 200\n",
        "lr = 0.002\n",
        "z_dim = 64\n",
        "display_step = 500\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "cifar10_shape = (3,32,32)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    CIFAR10('/content/drive/MyDrive/Colab Notebooks/DeepLearningAI/GANs/coursera-gan-specialization-main/Data',train=True, download= True, transform = transform),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "dataloader_test = DataLoader(\n",
        "    CIFAR10('/content/drive/MyDrive/Colab Notebooks/DeepLearningAI/GANs/coursera-gan-specialization-main/Data',train=False, download= True, transform = transform),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnjwNts6byiF",
        "outputId": "959be974-5243-4a77-ef33-6b0c44996e9f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_dimensions(z_dim, CIFAR10_shape, n_classes):\n",
        "    generator_input_dim = z_dim + n_classes\n",
        "    discriminator_im_chan = CIFAR10_shape[0] + n_classes\n",
        "    return generator_input_dim, discriminator_im_chan"
      ],
      "metadata": {
        "id": "elyK5x2vjOrY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_inp1, disc_inp1 = get_input_dimensions(z_dim, cifar10_shape, 10)\n",
        "\n",
        "gen = Generator(gen_inp1,3).to(device)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(),lr)\n",
        "disc = Discriminator(disc_inp1).to(device)\n",
        "disc_opt = torch.optim.Adam(disc.parameters(),lr)\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m,nn.Conv2d) or isinstance(m,nn.ConvTranspose2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight,0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias, 0)\n",
        "        \n",
        "gen = gen.apply(weights_init)\n",
        "disc = disc.apply(weights_init)"
      ],
      "metadata": {
        "id": "6SAdw0Bak_Tx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qD0zzDx0-U4G"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur_step = 0\n",
        "generator_losses = []\n",
        "discriminator_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for data,labels in tqdm(dataloader_train):\n",
        "        cur_batch_size = data.shape[0]\n",
        "\n",
        "        data = data.to(device)\n",
        "        noise = get_noise(cur_batch_size,z_dim,device)\n",
        "        one_hot = get_one_hot_labels(labels.to(device), 10)\n",
        "        #print(noise.shape,one_hot.shape)\n",
        "        gen_inp = combine_vectors(noise,one_hot)\n",
        "\n",
        "        image_one_hot = one_hot[:,:,None,None].repeat(1,1,cifar10_shape[1],cifar10_shape[2])\n",
        "        \n",
        "        disc_opt.zero_grad()\n",
        "\n",
        "        gen_out = gen(gen_inp)\n",
        "        disc_inp_fake = combine_vectors(gen_out.detach(), image_one_hot)\n",
        "        disc_inp_real = combine_vectors(data, image_one_hot)\n",
        "        disc_fake_pred = disc(disc_inp_fake)\n",
        "        disc_real_pred = disc(disc_inp_real)\n",
        "        disc_out = torch.cat((disc_fake_pred,disc_real_pred),dim=1)\n",
        "        actual_labels = torch.cat((torch.zeros_like(disc_fake_pred),torch.ones_like(disc_real_pred)),dim=1)\n",
        "        disc_loss = criterion(disc_out,actual_labels)\n",
        "\n",
        "        disc_fake_loss = criterion(disc_out,actual_labels)\n",
        "        disc_loss.backward(retain_graph=True)\n",
        "        disc_opt.step()\n",
        "        \n",
        "        discriminator_losses += [disc_loss.item()]\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "\n",
        "        disc_fake_pred = disc(disc_inp_fake)\n",
        "        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "\n",
        "        generator_losses += [gen_loss.item()]\n",
        "\n",
        "\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
        "            disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
        "            print(f\"Step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n",
        "            show_tensor_images(gen_out)\n",
        "            show_tensor_images(data)\n",
        "            step_bins = 20\n",
        "            x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n",
        "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
        "            plt.plot(\n",
        "                range(num_examples // step_bins), \n",
        "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                label=\"Generator Loss\"\n",
        "            )\n",
        "            plt.plot(\n",
        "                range(num_examples // step_bins), \n",
        "                torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
        "                label=\"Discriminator Loss\"\n",
        "            )\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "        elif cur_step == 0:\n",
        "            print(\"Working Now !\")\n",
        "        cur_step += 1\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "Pe1YHVhwnJ3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DbDs8Us9-Pbn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}